apiVersion: archon.kubeup.com/v1
kind: InstanceGroup
metadata:
  name: k8s-node
spec:
  replicas: 1
  selector:
    matchLabels:
      app: k8s-node
  template:
    metadata:
      annotations:
        initializers: archon.kubeup.com/public-ip,archon.kubeup.com/private-ip
      labels:
        app: k8s-node
    spec:
      networkName: k8s-net
      instanceType: ecs.n1.tiny
      os: CoreOS
      image: coreos681_64_40G_aliaegis_20160222.vhd
      hostname: {{ .Status.PrivateIP }}
      files:
      - name: coreos-update
        path: "/coreos/update"
        content: |-
          server: https://kubeup.com/coreos_update
      - name: unit-etcd2
        path: "/coreos/unit/etcd2"
        content: |-
          name: etcd2.service
          enable: false
      - name: unit-aliyun-update
        path: "/coreos/unit/aliyun-update"
        template: |-
          name: aliyun-update.service
          command: start
          content: |-
            [Service]
            ExecStart=/usr/bin/sh -c 'sleep 30 && update_engine_client -update && sleep 5 && systemctl reboot'
            User=root
      - name: unit-flexv
        path: "/coreos/unit/flexv"
        template: |-
          name: flexv.service
          enable: true
          content: |-
            [Service]
            ExecStart=/usr/bin/sh -c 'FLEXPATH=/opt/k8s/volume/plugins/aliyun~flexv; sudo mkdir $FLEXPATH -p; docker run -v $FLEXPATH:/opt {{ index .Configs "k8s" "kube-aliyun-img" }} cp /flexv /opt/'
            Restart=on-failure
            User=root
            [Install]
            WantedBy=multi-user.target
      - name: unit-kubelet
        path: "/coreos/unit/kubelet"
        template: |-
          name: kubelet.service
          enable: true
          content: |-
            [Unit]
            Wants=flexv.service
            After=flexv.service
            [Service]
            Environment=KUBELET_VERSION={{ index .Configs "k8s" "k8s-version"}}
            Environment=KUBELET_ACI={{ index .Configs "k8s" "kubelet-aci-img"}}
            Environment="RKT_OPTS=--uuid-file-save=/var/run/kubelet-pod.uuid \
              --volume dns,kind=host,source=/etc/resolv.conf \
              --mount volume=dns,target=/etc/resolv.conf \
              --volume var-log,kind=host,source=/var/log \
              --mount volume=var-log,target=/var/log \
              --volume lib-modules,kind=host,source=/lib/modules \
              --mount volume=lib-modules,target=/lib/modules \
              --volume k8s-opt,kind=host,source=/opt/k8s \
              --mount volume=k8s-opt,target=/opt/k8s \
              --volume var-cni,kind=host,source=/var/lib/cni \
              --mount volume=var-cni,target=/var/lib/cni"
            ExecStartPre=/usr/bin/mkdir -p /etc/kubernetes/manifests
            ExecStartPre=/usr/bin/mkdir -p /var/log/containers
            ExecStartPre=/usr/bin/mkdir -p /var/lib/cni
            ExecStartPre=-/usr/bin/rkt rm --uuid-file=/var/run/kubelet-pod.uuid
            ExecStart=/usr/lib/coreos/kubelet-wrapper \
              --api-servers={{ index .Configs "k8s" "api-servers"}} \
              --register-schedulable=true \
              --allow-privileged=true \
              --pod-manifest-path=/etc/kubernetes/manifests \
              --cluster-dns={{ index .Configs "k8s" "dns-service-ip"}} \
              --node-ip={{.Status.PrivateIP}} \
              --cluster-domain=cluster.local \
              --network-plugin=kubenet \
              --volume-plugin-dir=/opt/k8s/volume/plugins \
              --enable-controller-attach-detach \
              --kubeconfig=/etc/kubernetes/node-kubeconfig.yaml \
              --tls-cert-file=/etc/kubernetes/ssl/node.pem \
              --tls-private-key-file=/etc/kubernetes/ssl/node-key.pem
              --pod-infra-container-image={{ index .Configs "k8s" "pause-img"}}
            ExecStop=-/usr/bin/rkt stop --uuid-file=/var/run/kubelet-pod.uuid
            Restart=always
            RestartSec=10
            User=root
            [Install]
            WantedBy=multi-user.target
      - name: ca.pem
        path: "/etc/kubernetes/ssl/ca.pem"
        permissions: "0644"
        owner: "root"
        template: |-
          {{ index .Configs "k8s" "ca-cert" }}
      - name: node.pem
        path: "/etc/kubernetes/ssl/node.pem"
        permissions: "0644"
        owner: "root"
        template: |-
          {{ index .Secrets "node" "tls-cert" | printf "%s" }}
      - name: node-key.pem
        path: "/etc/kubernetes/ssl/node-key.pem"
        permissions: "0600"
        owner: "root"
        template: |-
          {{ index .Secrets "node" "tls-key" | printf "%s" }}
      - name: node-kubeconfig.yaml
        path: "/etc/kubernetes/node-kubeconfig.yaml"
        permissions: "0644"
        owner: "root"
        template: |-
          apiVersion: v1
          kind: Config
          clusters:
          - name: local
            cluster:
              certificate-authority: /etc/kubernetes/ssl/ca.pem
          users:
          - name: kubelet
            user:
              client-certificate: /etc/kubernetes/ssl/node.pem
              client-key: /etc/kubernetes/ssl/node-key.pem
          contexts:
          - context:
              cluster: local
              user: kubelet
            name: kubelet-context
          current-context: kubelet-context
      - name: kube-proxy.yaml
        path: "/etc/kubernetes/manifests/kube-proxy.yaml"
        permissions: "0644"
        owner: "root"
        template: |-
          apiVersion: v1
          kind: Pod
          metadata:
            name: kube-proxy
            namespace: kube-system
          spec:
            hostNetwork: true
            containers:
            - name: kube-proxy
              image: {{ index .Configs "k8s" "hyper-kube-img" }}
              command:
              - /hyperkube
              - proxy
              - --master={{ index .Configs "k8s" "api-servers" }}
              - --kubeconfig=/etc/kubernetes/node-kubeconfig.yaml
              securityContext:
                privileged: true
              volumeMounts:
              - mountPath: /etc/ssl/certs
                name: ssl-certs-host
                readOnly: true
              - mountPath: /etc/kubernetes/node-kubeconfig.yaml
                name: kubeconfig
                readOnly: true
              - mountPath: /etc/kubernetes/ssl
                name: etc-kube-ssl
                readOnly: true
            volumes:
            - hostPath:
                path: /usr/share/ca-certificates
              name: ssl-certs-host
            - hostPath:
                path: /etc/kubernetes/node-kubeconfig.yaml
              name: kubeconfig
            - hostPath:
                path: /etc/kubernetes/ssl
              name: etc-kube-ssl
      configs:
      - name: k8s
        data:
          hyper-kube-img: registry.aliyuncs.com/archon/hyperkube-amd64:v1.6.0-beta.2
          pause-img: registry.aliyuncs.com/archon/pause-amd64:3.0
          kubelet-aci-img: kubeup.com/aci/coreos/hyperkube
          kube-aliyun-img: registry.aliyuncs.com/kubeup/kube-aliyun
          api-servers: https://PUT_YOUR_MASTER_PRIVATE_IP_HERE
          dns-service-ip: 10.3.0.10
          k8s-version: v1.6.0-beta.3_coreos.0
          ca-cert: |-
            PUT YOUR CA CERTIFICATE HERE
      users:
      - name: core
    secrets:
    - metadata:
        name: node
        annotations:
            archon.kubeup.com/csr: |-
              {
                "CN": "{{ .Meta.Name }}",
                "hosts": [
                  "{{ .Meta.Name }}",
                  "{{ .Status.PrivateIP }}",
                  "{{ .Status.PublicIP }}"
                ],
                "key": {
                  "algo": "ecdsa",
                  "size": 256
                },
                "names": [
                  {
                    "C": "US",
                    "L": "CA",
                    "ST": "San Francisco"
                  }
                ]
              }
            archon.kubeup.com/status: Pending
            archon.kubeup.com/type: csr
      type: Opaque

